---
phase: 03-core-grading-experience
plan: 03
type: execute
wave: 3
depends_on: [03-01, 03-02]
files_modified:
  - src/api/app.py
  - src/api/schemas.py
autonomous: true
requirements:
  - GRAD-08
  - GRAD-09
user_setup: []

must_haves:
  truths:
    - "User can retrieve graded results via GET /api/sessions/{session_id}"
    - "User can update individual grades via PATCH /api/sessions/{session_id}/copies/{copy_id}/grades"
    - "Grade updates persist immediately and recalculate total scores"
    - "Session results persist across restarts via SessionStore"
    - "Review endpoint returns all grades with dual-LLM comparison data"
  artifacts:
    - path: "src/api/app.py"
      provides: "GET /sessions/{id}, PATCH /sessions/{id}/copies/{copy_id}/grades"
      exports: ["get_session", "update_grade"]
    - path: "src/api/schemas.py"
      provides: "UpdateGradeRequest, UpdateGradeResponse schemas"
      contains: "UpdateGradeRequest"
    - path: "src/storage/session_store.py"
      provides: "Session persistence via save_session/load_session"
      exports: ["SessionStore"]
  key_links:
    - from: "src/api/app.py"
      to: "src/storage/session_store.py"
      via: "SessionStore for loading and saving sessions"
      pattern: "SessionStore(session_id, user_id=user_id)"
    - from: "src/api/app.py"
      to: "src/core/models.py"
      via: "GradedCopy model updates"
      pattern: "graded.grades\[question_id\] = new_grade"
---

<objective>
Implement review endpoints for viewing and editing graded results with immediate persistence.

This plan enables the review workflow: retrieve all graded results with dual-LLM comparison data, edit individual grades, recalculate totals, and persist changes immediately.

Purpose: Allow teachers to review AI grading results, make manual adjustments, and ensure all changes are saved to user-scoped session storage.

Output: Enhanced GET /sessions/{id} endpoint, new PATCH /sessions/{id}/copies/{copy_id}/grades endpoint, update schemas.
</objective>

<execution_context>
@/home/olivier/.claude/get-shit-done/workflows/execute-plan.md
@/home/olivier/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/phases/03-core-grading-experience/03-CONTEXT.md
@.planning/phases/03-core-grading-experience/03-RESEARCH.md
@.planning/phases/03-core-grading-experience/03-01-PLAN.md
@.planning/phases/03-core-grading-experience/03-02-PLAN.md
@src/api/app.py
@src/api/schemas.py
@src/storage/session_store.py
@src/core/models.py

<interfaces>
<!-- From src/api/app.py - Existing GET /sessions/{id} endpoint (lines 682-732) -->
```python
@app.get("/api/sessions/{session_id}", response_model=SessionDetailResponse)
async def get_session(session_id: str, current_user = Depends(get_current_user)):
    """Get detailed session information."""
    user_id = current_user.id
    store = SessionStore(session_id, user_id=user_id)
    session = store.load_session()
    # Returns copies, graded_copies, question_weights
```

<!-- From src/storage/session_store.py - Session persistence -->
```python
class SessionStore:
    def __init__(self, session_id: str, user_id: str):
        # User-scoped storage path: data/sessions/{user_id}/{session_id}/

    def load_session(self) -> Optional[GradingSession]:
        """Load session from JSON file."""

    def save_session(self, session: GradingSession):
        """Save session to JSON file."""
```

<!-- From src/core/models.py - GradedCopy structure -->
```python
class GradedCopy(BaseModel):
    copy_id: str
    grades: Dict[str, float] = Field(default_factory=dict)  # {question_id: score}
    total_score: float = 0.0
    max_score: float = 0.0
    confidence: float = 0.5
    confidence_by_question: Dict[str, float] = Field(default_factory=dict)
    feedback: Optional[str] = None
    student_feedback: Optional[Dict[str, str]] = None
    grading_audit: Optional[GradingAudit] = None  # Contains dual-LLM comparison
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add grade update schemas</name>
  <files>src/api/schemas.py</files>
  <action>
Add Pydantic schemas for grade update endpoint:

```python
class UpdateGradeRequest(BaseModel):
    question_id: str = Field(..., description="Question identifier (e.g., 'Q1', '2')")
    new_grade: float = Field(..., ge=0, description="New grade value (non-negative)")
    auto_recalc: bool = True
    """If True, automatically recalculate total_score. If False, caller provides total_score."""

    @field_validator('new_grade')
    @classmethod
    def validate_grade(cls, v: float, info) -> float:
        # Basic validation: non-negative
        # Max point validation happens in endpoint (needs session context)
        if v < 0:
            raise ValueError('Grade must be non-negative')
        return v

class UpdateGradeResponse(BaseModel):
    success: bool
    copy_id: str
    question_id: str
    old_grade: float
    new_grade: float
    old_total: float
    new_total: float
    max_score: float
```

Add to SessionDetailResponse if missing - should include:
- graded_copies with full grading_audit data for dual-LLM display
- question_weights for reference
- session status
</action>
  <verify>
grep -n "UpdateGradeRequest\|UpdateGradeResponse" src/api/schemas.py
</verify>
  <done>
Pydantic schemas define grade update request/response contracts with validation.
</done>
</task>

<task type="auto">
  <name>Task 2: Add grade update endpoint</name>
  <files>src/api/app.py</files>
  <action>
Add new endpoint PATCH /api/sessions/{session_id}/copies/{copy_id}/grades:

```python
@app.patch("/api/sessions/{session_id}/copies/{copy_id}/grades", response_model=UpdateGradeResponse)
async def update_grade(
    session_id: str,
    copy_id: str,
    request: UpdateGradeRequest,
    current_user = Depends(get_current_user)
):
    """
    Update a single question grade for a graded copy.

    Recalculates total_score automatically unless auto_recalc=False.
    Persists changes immediately to user-scoped session storage.
    """
    user_id = current_user.id
    store = SessionStore(session_id, user_id=user_id)
    session = store.load_session()

    if not session:
        raise HTTPException(status_code=404, detail="Session not found")

    # Find the graded copy
    graded = next((g for g in session.graded_copies if g.copy_id == copy_id), None)
    if not graded:
        raise HTTPException(status_code=404, detail="Graded copy not found")

    # Validate question_id exists
    if request.question_id not in graded.grades:
        raise HTTPException(status_code=400, detail="Question not found in graded copy")

    # Validate new_grade against max points for this question
    max_points = session.policy.question_weights.get(request.question_id)
    if max_points is not None and request.new_grade > max_points:
        raise HTTPException(
            status_code=400,
            detail=f"Grade {request.new_grade} exceeds max points {max_points} for {request.question_id}"
        )

    # Store old values
    old_grade = graded.grades[request.question_id]
    old_total = graded.total_score

    # Update grade
    graded.grades[request.question_id] = request.new_grade

    # Recalculate total
    if request.auto_recalc:
        graded.total_score = sum(graded.grades.values())

    # Persist immediately
    store.save_session(session)

    return UpdateGradeResponse(
        success=True,
        copy_id=copy_id,
        question_id=request.question_id,
        old_grade=old_grade,
        new_grade=request.new_grade,
        old_total=old_total,
        new_total=graded.total_score,
        max_score=graded.max_score
    )
```

Ensure:
- Multi-tenant isolation via SessionStore(user_id=user_id)
- Validation against question max points
- Immediate persistence via store.save_session()
- Returns old/new values for UI feedback
</action>
  <verify>
grep -n "@app.patch.*copies.*grades\|async def update_grade" src/api/app.py
</verify>
  <done>
PATCH endpoint updates individual grades, validates against max points, recalculates totals, and persists immediately.
</done>
</task>

<task type="auto">
  <name>Task 3: Enhance session detail endpoint for review</name>
  <files>src/api/app.py</files>
  <action>
Enhance GET /api/sessions/{session_id} to return complete dual-LLM data for review display.

Update the get_session endpoint (around line 682) to include:

1. **grading_audit in graded_copies**: Ensure SessionDetailResponse.graded_copies includes full grading_audit with llm_results, providers, and resolution data
2. **student_feedback**: Include per-question student feedback if available
3. **confidence_by_question**: Include confidence scores for each question
4. **disagreement_count**: Add field showing how many questions had LLM disagreements

Add calculation:

```python
disagreement_count = 0
for graded in session.graded_copies:
    if graded.grading_audit:
        for qaudit in graded.grading_audit.questions.values():
            if not qaudit.resolution.agreement:
                disagreement_count += 1
```

Ensure SessionDetailResponse schema in schemas.py includes these fields or update it:

```python
class GradedCopyDetail(BaseModel):
    copy_id: str
    student_name: Optional[str] = None
    total_score: float
    max_score: float
    confidence: float
    confidence_by_question: Dict[str, float] = Field(default_factory=dict)
    grades: Dict[str, float]
    feedback: Optional[str] = None
    student_feedback: Optional[Dict[str, str]] = None
    grading_audit: Optional[Dict[str, Any]] = None  # Full dual-LLM data
    has_disagreements: bool = False
```

This allows the review UI to display side-by-side LLM results with disagreement highlighting.
</action>
  <verify>
grep -n "grading_audit\|confidence_by_question\|disagreement" src/api/app.py | grep -A2 "def get_session"
</verify>
  <done>
Session detail endpoint returns complete graded data including dual-LLM comparison, confidence scores, and disagreement indicators.
</done>
</task>

</tasks>

<verification>
1. Complete a grading session with dual-LLM mode
2. GET /api/sessions/{id} - verify response includes:
   - graded_copies with grading_audit
   - confidence_by_question for each copy
   - disagreement_count or has_disagreements flags
3. PATCH /api/sessions/{id}/copies/{copy_id}/grades with:
   ```json
   {"question_id": "Q1", "new_grade": 4.0}
   ```
4. Verify response returns old_grade, new_grade, old_total, new_total
5. GET /api/sessions/{id} again - verify total_score is updated and persisted
6. Try updating with grade exceeding max_points - verify 400 error
7. Try updating non-existent question - verify 400 error
</verification>

<success_criteria>
1. GET /sessions/{id} returns complete graded data with dual-LLM audit trail
2. PATCH /sessions/{id}/copies/{copy_id}/grades updates individual grades
3. Grade updates validate against question max_points
4. Total scores recalculate automatically after grade changes
5. All changes persist immediately via SessionStore.save_session()
6. Multi-tenant isolation enforced via user_id
</success_criteria>

<output>
After completion, create `.planning/phases/03-core-grading-experience/03-03-SUMMARY.md` with:
- Review endpoint response structure
- Grade update validation rules
- Persistence behavior
</output>
